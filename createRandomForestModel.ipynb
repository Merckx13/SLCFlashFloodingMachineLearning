{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import cohen_kappa_score as kappa\n",
    "import sklearn.ensemble as ens\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import matplotlib\n",
    "#matplotlib.use('tkagg')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a method to divide the training data. \n",
      "    Enter '1' for random, '2' or just <enter> for specific years: \n",
      "\n",
      "\n",
      "Enter years for training, either comma separated for each year or a range divided by a dash. \n",
      "    Default is '2011-2015' for training, or just <enter>: \n",
      "\n",
      "\n",
      "Run on each subdivided group of basins (e.g. KSGU) or all at once (KBCE only)?\n",
      "   If running on all at once, you will have the option to run the program iteratively\n",
      "   to obtain a desired skill level.\n",
      "   Enter '1' to see the results for each basin, '2' or just <enter> for all in one:\n",
      " \n",
      "\n",
      "\n",
      "Select a model for the BUFR sounding. \n",
      "   Enter '1' for RAP, '2' or just <enter> for NAM: \n",
      "\n",
      "\n",
      "Display reliability plot of # of flooding vs probabilistic output? \n",
      "   Enter '1' for yes, '2' or just <enter> for no: 1\n",
      "\n",
      "\n",
      "Calculate stats for RRA and blended RRA/RandomForest? \n",
      "   Enter '1' for no, '2' or just <enter> for yes: \n",
      "\n",
      "\n",
      "Run multiple times (iteratively) to reach a target accuracy? \n",
      "   Enter '1' for yes, '2' or just <enter> for no: \n",
      "\n",
      "\n",
      "Save the Random Forest Model for the RRA tool? \n",
      "   Enter '1' for yes, '2' or just <enter> for no: \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = input(\"Select a method to divide the training data. \\n\" + \\\n",
    "                 \"    Enter '1' for random, '2' or just <enter> for specific years: \")\n",
    "print('\\n')\n",
    "\n",
    "if len(response) == 0 or response == '2':\n",
    "   response2 = input(\"Enter years for training, either comma separated for each year or a range divided by a dash. \\n\" +\n",
    "               \"    Default is '2011-2015' for training, or just <enter>: \")\n",
    "   print('\\n')\n",
    "   if ',' in response2:\n",
    "      trainingYearsList = list(map(int, response2.split(\",\")))\n",
    "   elif '-' in response2:\n",
    "      firstYear = datetime.strptime(str(response2[0:response2.find('-')]),'%Y')\n",
    "      secondYear = datetime.strptime(str(response2[response2.find('-')+1:len(response2)]),'%Y')\n",
    "      trainingYearsList = range(firstYear.year, secondYear.year+1)\n",
    "   elif len(response2) == 0:\n",
    "      trainingYearsList = [2011, 2012, 2013, 2014, 2015]\n",
    "   else:\n",
    "      print(\"please use the format indicated in the prompts\")\n",
    "      sys.exit()   \n",
    "   testingYearsList = [x for x in availableYears if x not in trainingYearsList]\n",
    "\n",
    "response3 = input(\"Run on each subdivided group of basins (e.g. KSGU) or all at once (KBCE only)?\\n\" + \\\n",
    "                  \"   If running on all at once, you will have the option to run the program iteratively\\n\" + \\\n",
    "\t\t  \"   to obtain a desired skill level.\\n\" + \\\n",
    "                  \"   Enter '1' to see the results for each basin, '2' or just <enter> for all in one:\\n \") \n",
    "print('\\n')\n",
    "\n",
    "response4 = input(\"Select a model for the BUFR sounding. \\n\" + \\\n",
    "                  \"   Enter '1' for RAP, '2' or just <enter> for NAM: \")\n",
    "print('\\n')\n",
    "\n",
    "#response5 = input(\"Display plots of # of basins flooded vs probabilistic output? \\n\" + \\\n",
    "#                  \"   Enter '1' for yes, '2' or just <enter> for no: \")\n",
    "#print('\\n')\n",
    "\n",
    "response5 = input(\"Display reliability plot of # of flooding vs probabilistic output? \\n\" + \\\n",
    "                  \"   Enter '1' for yes, '2' or just <enter> for no: \")\n",
    "print('\\n')\n",
    "\n",
    "response6 = input(\"Calculate stats for RRA and blended RRA/RandomForest? \\n\" + \\\n",
    "                  \"   Enter '1' for no, '2' or just <enter> for yes: \")\n",
    "print('\\n')\n",
    "\n",
    "response7 = input(\"Run multiple times (iteratively) to reach a target accuracy? \\n\" + \\\n",
    "                  \"   Enter '1' for yes, '2' or just <enter> for no: \")\n",
    "print('\\n')\n",
    "\n",
    "if response7 == '1':\n",
    "    response8 = input(\"Target metric for an 'accurate' forecast: \\n\" + \\\n",
    "                      \"   Enter '1' for Cohen's Kappa (deterministic), '2' or just <enter> for Brier (probabilistic): \")\n",
    "    print('\\n')\n",
    "    \n",
    "    if response8 == '1':\n",
    "        response9 = input(\"Target Cohen's Kappa: \\n\" + \\\n",
    "                          \"   E.g, 0.35: \")\n",
    "        print('\\n')\n",
    "    else:\n",
    "        response9 = input(\"Target Brier Score: \\n\" + \\\n",
    "                          \"   E.g, 0.07: \")\n",
    "        print('\\n') \t\t      \t\t\t  \n",
    "\n",
    "response10 = input(\"Save the Random Forest Model for the RRA tool? \\n\" + \\\n",
    "                  \"   Enter '1' for yes, '2' or just <enter> for no: \")\n",
    "print('\\n') \n",
    "\n",
    "response11 = input(\"Search for optimal hyperparameters (increases runtime)? \\n\" + \\\n",
    "                  \"   Enter '1' for yes, '2' or just <enter> for no: \")\n",
    "print('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "availableYears = [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018]\n",
    "sites = [\"K4HV\",\"KBCE\",\"KPGA\",\"KSGU\"]\n",
    "\n",
    "if len(response4) == 0 or response4 == '2':\n",
    "   model = \"NAM\"\n",
    "else:\n",
    "   model = \"RAP\"\n",
    "\n",
    "# percent of dataset to turn into test cases for wetter and drier locations based on number of flash floods\n",
    "drySitesPercentage = 30\n",
    "wetSitesPercentage = 30\n",
    "\n",
    "drySites = [\"K4HV\",\"KSGU\"]\n",
    "\n",
    "# default to the wetter sites percentage\n",
    "percentToTest = wetSitesPercentage\n",
    "\n",
    "THERMO = ['MUCAPE', 'DCAPE', '7-5LR', 'LCL','PW', 'MeanRH','DD', 'WC', 'SfcTd', 'SfcT']\n",
    "\n",
    "KIN = ['0-6km Shear Dir', '0-6km Shear Mag', 'C Dn Dir',\n",
    "       'C Dn Mag', 'C Up Dir', 'C Up Mag', 'SM Dir','SM Mag',\n",
    "       'MW Dir','MW Mag', '4-6km dir',\n",
    "       '4-6km mag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createReliabilityPlots(response5, response6, ytest, yprob, yprob2, yprob3):\n",
    "      if response5 == '1':\n",
    "         #slope,intercept,r_value,p_value,std_err = stats.linregress(test_df['Basins'], yprob) \n",
    "         #plt.figure()\n",
    "         #plt.suptitle('Random Forest Probabilistic Forecast vs # of Basins Flooded for ' + site)\n",
    "         #plt.scatter(yprob, test_df['Basins'], s=75, color='red', zorder=200, edgecolor='maroon',label='# of Basins Flooded')\n",
    "         \n",
    "         clf_score = brier_score_loss(ytest, yprob)\n",
    "         plt.figure() \n",
    "         fraction_of_positives, mean_predicted_value = calibration_curve(ytest, yprob, n_bins=10)\n",
    "         plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly Calibrated\")\n",
    "         plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"%s (%1.3f)\" % (\"Random Forest Model\", clf_score))\n",
    "         if response6 == '2' or len(response6) == 0:\n",
    "            clf_score = brier_score_loss(ytest, yprob2)\n",
    "            plt.figure() \n",
    "            fraction_of_positives, mean_predicted_value = calibration_curve(ytest, yprob2, n_bins=10)\n",
    "            plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly Calibrated\")\n",
    "            plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"%s (%1.3f)\" % (\"Legacy RRA\", clf_score))\t \n",
    "\n",
    "            clf_score = brier_score_loss(ytest, yprob3)\n",
    "            plt.figure() \n",
    "            fraction_of_positives, mean_predicted_value = calibration_curve(ytest, yprob3, n_bins=10)\n",
    "            plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly Calibrated\")\n",
    "            plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"%s (%1.3f)\" % (\"Blended RRA & Random Forest\", clf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneHyperparameters(xtrain, ytrain):\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 20000, num = 10)]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "\t\t   'max_depth': max_depth,\n",
    "\t\t   'min_samples_split': min_samples_split,\n",
    "\t\t   'min_samples_leaf': min_samples_leaf,\n",
    "\t\t   'bootstrap': bootstrap}\n",
    "    clf = ens.RandomForestClassifier()\n",
    "    clfRandom = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 100,\n",
    "                                   cv = 3, random_state = 42, n_jobs = -1)\n",
    "    clfRandom.fit(xtrain, ytrain)\n",
    "    print(clfRandom.best_params_)\n",
    "    return(clfRandom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == \"NAM\":\n",
    "   #fileString = '/common/2018FFW_study/*clean_nam.csv'\n",
    "   fileString = 'csv/*.csv'\n",
    "elif model == \"RAP\":\n",
    "   fileString = 'csv/*full_clean.csv'\n",
    "for csv in glob.glob(fileString):\n",
    "   \n",
    "   probabilisticOutput = []\n",
    "   deterministicOutput = []\n",
    "\n",
    "   if model == \"NAM\":\n",
    "      #site = csv[-18:-14]\n",
    "      site = csv[-8:-4]\n",
    "   elif model == \"RAP\":\n",
    "      site = csv[-19:-15]\n",
    "\n",
    "   if site == '/4HV':\n",
    "      site = 'K4HV'\n",
    "   elif site == '4HV_':\n",
    "      site = 'K4HV'\n",
    "\n",
    "   if response3 == '2' or len(response3) == 0:\n",
    "      if site != 'KBCE':\n",
    "         continue\n",
    "\n",
    "   # loop as needed to reach target metrics\n",
    "   targetAccuracy = False   \n",
    "   while not targetAccuracy:\n",
    "\n",
    "      if site in drySites:\n",
    "         percentToTest = drySitesPercentage\n",
    "      else:\n",
    "         percentToTest = wetSitesPercentage\n",
    "\n",
    "      df = pd.read_csv(csv)\n",
    "      \n",
    "      # Trim to Nick's RAP dates\n",
    "      #dfTrimmed = pd.read_csv(csv.replace('clean_nam', 'full_clean'))   \n",
    "      #dfIntersection = pd.merge(df, dfTrimmed, how='inner', on=['Date'], suffixes=('','_y'))\n",
    "      #cols = [c for c in dfIntersection.columns if c.lower()[-2:] != '_y']\n",
    "      #dfIntersection = dfIntersection[cols]\n",
    "      #dfInsersection = dfIntersection[dfIntersection.columns.drop('Unnamed: 0')]\n",
    "      #df = dfIntersection\n",
    "      \n",
    "      if site == 'KBCE':\n",
    "         df.loc[(df['Basins'] == 3), 'Result'] = 1\n",
    "      if '4HV' or 'SGU' in site_name:\n",
    "         df.loc[(df['Basins'] == 1), 'Result'] = 1\n",
    "      df2 = df.dropna(subset=KIN + THERMO + ['Basins'] + ['Result'] + ['deterministicRRA'] + ['probabilisticRRA'])\n",
    "\n",
    "      result = df2['Result']\n",
    "      predictors = df2[THERMO + KIN]\n",
    "\n",
    "      if response == '1': # use random split\n",
    "         xtrain, xtest, ytrain, ytest = train_test_split(predictors, result, test_size = percentToTest/100)\n",
    "         test_df = df.iloc[xtest.index.tolist()]\n",
    "\n",
    "      if len(response) == 0 or response == '2':\n",
    "         training_df = df2\n",
    "         test_df = df2\n",
    "         for year in testingYearsList:\n",
    "            training_df = training_df[training_df['Year'] != year]\n",
    "         for year in trainingYearsList:\n",
    "            test_df = test_df[test_df['Year'] != year] \t  \n",
    "         xtrain = training_df[THERMO + KIN]\n",
    "         xtest = test_df[THERMO + KIN]\n",
    "         ytrain = training_df.pop('Result')\n",
    "         ytest = test_df.pop('Result')\n",
    "\n",
    "      if len(response11) == 0 or response11 == '2':\n",
    "         #clf = ens.RandomForestClassifier(n_estimators=2000, max_depth=15, min_samples_leaf=4,\n",
    "         #                          \tmin_samples_split=4,oob_score=True,\n",
    "         #                          \tclass_weight='balanced')\n",
    "         # Updated numbers 6/11/19 based on hyperparameter optimization\n",
    "         clf = ens.RandomForestClassifier(n_estimators=2400, max_depth=30, min_samples_leaf=1,\n",
    "                                      \tmin_samples_split=5,oob_score=True,\n",
    "                                \tclass_weight='balanced')\n",
    "         clf.fit(xtrain, ytrain)\t\t\t\t\t\n",
    "      else:\n",
    "         clf = tuneHyperparameters(xtrain, ytrain)\t\t\t     \n",
    "\n",
    "      y_pred = clf.predict(xtest)\n",
    "      accuracy = metrics.accuracy_score(ytest, y_pred)\n",
    "      yprob = clf.predict_proba(xtest)[0:, 1]\n",
    "      #yprob = (yprob+yprob2)/2\n",
    "      brier_score = metrics.brier_score_loss(ytest, yprob)\n",
    "      auc = metrics.roc_auc_score(ytest, yprob)\n",
    "      cm = metrics.confusion_matrix(ytest, y_pred)\n",
    "      index_names = ['No Flooding Observed', 'Flooding Observed']\n",
    "      col_names = ['No Flooding Forecast', 'Flooding Forecast']\n",
    "      cm_df = pd.DataFrame(cm, columns =col_names, index=index_names)\n",
    "      ck = kappa(ytest, y_pred)\n",
    "      print('\\n\\n')\n",
    "      if 'trainingYearsList' in locals():\n",
    "         print('FFW model results for ' + site + ' using the ' + model + ', testing on ' + str(testingYearsList))\n",
    "      else:\n",
    "         print('FFW model results for ' + site + ' using the ' + model + ', testing on ' + str(percentToTest) + '% of the 2011-2018 dataset')\n",
    "      print('Probabilistic Verification')\n",
    "      print('Brier Score {:3.2f}, '.format(brier_score) +\n",
    "             'AUC = {:3.2f} '.format(auc))\n",
    "      print('Deterministic Verification')\n",
    "      print('Accuracy = {:3.2f}, '.format(accuracy) +\n",
    "              'Cohen\\'s Kappa {:3.2f}'.format(ck))\n",
    "      print(cm_df.head())\n",
    "\n",
    "      if response6 == '2' or len(response6) == 0:\n",
    "         yprob2 = test_df['probabilisticRRA']\n",
    "         y_pred2 = test_df['deterministicRRA']\n",
    "         auc = metrics.roc_auc_score(ytest, yprob2)\n",
    "         brier_score = metrics.brier_score_loss(ytest, yprob2)\n",
    "         accuracy = metrics.accuracy_score(ytest, y_pred2)\n",
    "         cm = metrics.confusion_matrix(ytest, y_pred2)   \n",
    "         cm_df = pd.DataFrame(cm, columns =col_names, index=index_names)\n",
    "         ck = kappa(ytest, y_pred2)\n",
    "         if 'trainingYearsList' in locals():\n",
    "            print('\\nSLC RRA verification for ' + site + ' using the ' + model + ', testing on ' + str(testingYearsList))\n",
    "         else:\n",
    "            print('\\nSLC RRA verification for ' + site + ' using the ' + model + ', testing on ' + str(percentToTest) + '% of the 2011-2018 dataset')\n",
    "         print('Probabilistic Verification')\n",
    "         print('Brier Score {:3.2f}, '.format(brier_score) +\n",
    "                'AUC = {:3.2f} '.format(auc))\n",
    "         print('Deterministic Verification')\n",
    "         print('Accuracy = {:3.2f}, '.format(accuracy) +\n",
    "                 'Cohen\\'s Kappa {:3.2f}'.format(ck))\n",
    "         print(cm_df.head())\n",
    "\n",
    "         yprob3 = (test_df['probabilisticRRA'] + yprob)/2\n",
    "         y_pred3 = round(yprob3)\n",
    "         auc = metrics.roc_auc_score(ytest, yprob3)\n",
    "         brier_score = metrics.brier_score_loss(ytest, yprob3)\n",
    "         accuracy = metrics.accuracy_score(ytest, y_pred3)\n",
    "         cm = metrics.confusion_matrix(ytest, y_pred3)   \n",
    "         cm_df = pd.DataFrame(cm, columns =col_names, index=index_names)\n",
    "         ck = kappa(ytest, y_pred3)\n",
    "         if 'trainingYearsList' in locals():   \n",
    "            print('\\nSLC combined verification for ' + site + ' using the ' + model + ', testing on ' + str(testingYearsList))\n",
    "         else:\n",
    "            print('\\nSLC combined verification for ' + site + ', testing on ' + str(percentToTest) + '% of the 2011-2018 dataset')\n",
    "         print('Probabilistic Verification')\n",
    "         print('Brier Score {:3.2f}, '.format(brier_score) +\n",
    "        \t'AUC = {:3.2f} '.format(auc))\n",
    "         print('Deterministic Verification')\n",
    "         print('Accuracy = {:3.2f}, '.format(accuracy) +\n",
    "        \t 'Cohen\\'s Kappa {:3.2f}'.format(ck))\n",
    "         print(cm_df.head())\n",
    "\n",
    "      print('\\n\\n')\n",
    "\n",
    "      saveFile = 'savedModel_' + site + '.pck'\n",
    "      if response7 != '1':\n",
    "         targetAccuracy = True\n",
    "         createReliabilityPlots(response5, response6, ytest, yprob, yprob2, yprob3)\n",
    "         if response10 == '1':\n",
    "            pickle.dump(clf, open(saveFile, 'wb'))\t \t \n",
    "      else:\n",
    "         if response8 == '1':\n",
    "            if ck > float(response9):\n",
    "               targetAccuracy = True\n",
    "               createReliabilityPlots(response5, response6, ytest, yprob, yprob2, yprob3)\n",
    "               if response10 == '1':\n",
    "                   pickle.dump(clf, open(saveFile, 'wb'))\n",
    "            else:\n",
    "               print(\"Didn't reach target Cohen's Kappa of \"+str(response9)+\", only reached \"+str(ck)+\", trying again\")\t\n",
    "         else:\n",
    "            if brier_score < float(response9):\n",
    "               targetAccuracy = True\n",
    "               createReliabilityPlots(response5, response6, ytest, yprob, yprob2, yprob3)\n",
    "               if response10 == '1':\n",
    "                   pickle.dump(clf, open(saveFile, 'wb'))\t       \n",
    "            else:\n",
    "               print(\"Didn't reach target Brier Skill Score of \"+str(response9)+\", only reached \"+str(brier_score)+\", trying again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
